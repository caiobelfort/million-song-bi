# Project Roadmap

# 1 - Transform the dataset in postgres tables

# 2 - Create simulation events with [eventsim](https://github.com/Interana/eventsim)

# 3 - Modeling a Star Schema for the data

# 4 - Create pipelines for moving data from relational format to the star schema using python only

# 6 - Create Apache Superset dashboards

# 5 - Repeat the step 4 using Airflow.

# 6 - Create a Data Lake using MinIO/Apache Hudi using generated data to support the final Star Schema

# 7 - Add debezium to postgres to enable Change Data Capture with Kafka to enable real time processing in Apache Hudi

# 8 - Use Apache Flink to do something with real time processing. Maybe some machine learning...



    


